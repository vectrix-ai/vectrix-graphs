{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Searchflow\n",
    "\n",
    "### Packages needed to run this notebook\n",
    "- libmagic: ```brew install libmagic```\n",
    "\n",
    "### ChromaDB\n",
    "Don't forget to start the ChromaDB server: ```docker run -p 7777:8000 chromadb/chroma```\n",
    "\n",
    "### Run the API\n",
    "https://docs.astral.sh/uv/guides/integration/fastapi/\n",
    "\n",
    "For development purposes, you can run the API with: ```uv run fastapi dev```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load packages from the src directory\n",
    "import sys\n",
    "import json\n",
    "sys.path.append('../src')\n",
    "from vectrix_graphs import ExtractDocuments, setup_logger, ExtractMetaData\n",
    "\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting chunks of data from a document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-10-26 16:56:20,964 - Files - INFO - Extracting documents from ./files/attention_is_all_you_need.pdf\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Create chunks of data from a document\n",
    "extract = ExtractDocuments(\n",
    "    logger=setup_logger(name=\"Files\", level=\"INFO\"),\n",
    "    )\n",
    "\n",
    "result = extract.extract(file_path=\"./files/attention_is_all_you_need.pdf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata:\n",
      "{\n",
      "    \"file_directory\": \"./files\",\n",
      "    \"filename\": \"attention_is_all_you_need.pdf\",\n",
      "    \"languages\": [\n",
      "        \"eng\"\n",
      "    ],\n",
      "    \"last_modified\": \"2024-10-22T21:44:24\",\n",
      "    \"page_number\": 1,\n",
      "    \"orig_elements\": \"eJx1VE2P2zYQ/SsDnS3VlrW73j0G2ObSjwB1kMNiYVDSWCJKkQpJ+aNB/nvfUFq3TZOTzSFn5s17T/PyJWPDA9t40G32RFn9uK5rVT7k3KhtXlUt5+q+2eYll6pudmtW24dsRdnAUbUqKuR8yRrnfKutihzS2airm+KhZ931EZGHxxIpS/Ss29gjeL+R4Oi0jZL18rKptsX9iqrNtihfV/R2vnu4K3Zyru4fi93/z/N7BLJwDZEHmeKDvrD5Y1QNZ19xcdSGD6323ETnr/Kg+EliIVsurRpYwipGUKGdPehwUMYcgPhgmdtibI9ZmsF2k+rSnC8Z2y57TdEQD4Nr9VFzYrFcl1W+WedluS83T1X1VFaSPSLzYKehZo9XG4EW+SIMZfueqXUDSLSRAn+e2DZM0Ssb2qkRSIQGbAIpz1SrwC0h1rhhNHwhjDZ5D+zkPIL25MwkScqQ5cmnn3h2/s9AsVeRtG3M1DIpS2iEwh5/W1LUcjoVJIBqDpFG9kfngay7ITDBSRMLPlGO/1NiKYC4d1PXS4cbqzRw0yurw1DQJ6bRu9EFgAC4MwUto7zhxJhNryM6TJ5XqcteyBAo7FcLA8EZNlch4js9wopaHUa2QbCfdexvNDWcsP6LqECS7lGtoOcLZtbyUQQpDTw0KKCxiyBGpUZRBdAZencWeJhjoSc6EEdhkiJQQ1v6PCmj45XOPbyGy5lL6DgqSIMR9F+qNjMmD+21lxdBdxaOauAIzAi3ojRQSX3A0Lag3yc/NyWBxycOVO6Kit798vwxIQdrn37dU7neVPRsO6NDnyM/f89+gDDfTrMiaODdSbq7UxIR4l50iBJJbvAcJhNB7ewgiYNgHgAfwfo655UJAgD+AAMg/Cwy9N+B4G5DoR9owXvM9eYRFOB8vsZt5Nwdc7TIlY/z2KERYt0Re6HYkTpGGUPoEqhwD22LO2rVNUmbFhS9//AR2BWFAWLQ0av5e0MNAX9LblwQQ8zRRMYi+NG7IQUhMnsljk3+Xqyh4rf2pY4tHkJ2THZmNIWmDo/8YirwqMbRXKWtxj6YmgbyHycDI+DpQqP4F9JE2RVX8VIyeo1Cs9uN8t1sKqMHQGv/mUVWdyErKV7HtPl+Ux7I9Yn3spC+vv4N8OQegg==\",\n",
      "    \"filetype\": \"application/pdf\"\n",
      "}\n",
      "Content:\n",
      "The dominant sequence transduction models are based on complex recurrent or convolutional neural networks that include an encoder and a decoder. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English- to-German translation task, improving over the existing best results, including ensembles, by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the\n"
     ]
    }
   ],
   "source": [
    "print('Metadata:')\n",
    "print(json.dumps(result[1].metadata, indent=4))\n",
    "\n",
    "print('Content:')\n",
    "print(result[1].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-10-26 16:56:25,890 - ExtractMetaData - INFO - Extracting metadata from 52 documents, using llama3.1-70B\u001b[0m\n",
      "\u001b[31m2024-10-26 16:56:31,776 - ExtractMetaData - ERROR - Error during batch processing: Error code: 429 - {'error': {'message': 'Request was rejected due to request rate limiting. Your rate limits are 600 RPM (10 QPS) and 180000 TPM (3000 TPS). See details: https://docs.together.ai/docs/rate-limits', 'type': 'credit_limit', 'param': None, 'code': None}}\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Add additional metadata using a NER-pipeline\n",
    "ner = ExtractMetaData(\n",
    "    logger=setup_logger(name=\"ExtractMetaData\", level=\"INFO\",),\n",
    "    model=\"llama3.1-70B\" # Options are gpt-4o-mini, llama3.1-8B , llama3.1-70B\n",
    "    )\n",
    "result_with_metadata = ner.extract(result, source=\"uploaded_file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'filename': 'attention_is_all_you_need.pdf',\n",
       " 'filetype': 'application/pdf',\n",
       " 'author': '',\n",
       " 'source': 'uploaded_file',\n",
       " 'word_count': 107,\n",
       " 'language': '',\n",
       " 'content_type': '',\n",
       " 'tags': '',\n",
       " 'summary': '',\n",
       " 'read_time': 0.535,\n",
       " 'last_modified': '2024-10-22T21:44:24'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_with_metadata[0].metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding the documents to a vector database (Chroma)\n",
    "\n",
    "For this demo, the vector database will be saved locally on disk, restarting the container will delete the database.\n",
    "I prefer using the cosine distance instead of the default squared L2 distance, we pass this using the `hnsw:space` metadata.\n",
    "\n",
    "$$\n",
    "d = 1.0 - \\frac{\\sum(A_i \\times B_i)}{\\sqrt{\\sum(A_i^2) \\cdot \\sum(B_i^2)}}\n",
    "$$\n",
    "\n",
    "We use Ollama to calculate the embeddings locally with BGE-M3, since over a 100 langues are supported this is ideal for embedding Arabic documents.\n",
    "\n",
    "BGE-M3 is based on the XLM-RoBERTa architecture and is distinguished for its versatility in Multi-Functionality, Multi-Linguality, and Multi-Granularity:\n",
    "\n",
    "- Multi-Functionality: It can simultaneously perform the three common retrieval functionalities of embedding model: dense retrieval, multi-vector retrieval, and sparse retrieval.\n",
    "- Multi-Linguality: It can support more than 100 working languages.\n",
    "- Multi-Granularity: It is able to process inputs of different granularities, spanning from short sentences to long documents of up to 8192 tokens.\n",
    "\n",
    "> ℹ️ So all embeddings will be calculated locally ℹ️\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vectrix_graphs import vectordb\n",
    "\n",
    "vectordb.remove_collection(\"demo\")\n",
    "vectordb.create_collection(\"demo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectordb.add_documents(result_with_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's query the vector database\n",
    "vectordb.similarity_search(\n",
    "    query=\"What is the attention mechanism?\",\n",
    "    k=3\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Asking questions to the Graph\n",
    " Let's now ask questions using the LangGraph workflow\n",
    "\n",
    "### Example 1: Using closed source LLMs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2: Using open-source LLMs that can be self-hosted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load packages from the src directory\n",
    "import sys\n",
    "from IPython.display import Markdown, display, Image\n",
    "sys.path.append('../src')\n",
    "\n",
    "from langchain_core.messages import HumanMessage\n",
    "from vectrix_graphs import local_slm_demo\n",
    "\n",
    "# Display the graph\n",
    "display(Image(local_slm_demo.get_graph().draw_mermaid_png()))\n",
    "\n",
    "#Ask the question\n",
    "input = [HumanMessage(content=\"What is the attention mechanism?\")]\n",
    "\n",
    "\n",
    "# Run the graph\n",
    "response = await local_slm_demo.ainvoke({\"messages\": input})\n",
    "display(Markdown(f\"***Question:*** \\n {input[0].content}\\n\"))\n",
    "display(Markdown(response['messages'][-1].content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load packages from the src directory\n",
    "import sys\n",
    "import json\n",
    "from IPython.display import Markdown, display, Image\n",
    "sys.path.append('../src')\n",
    "\n",
    "from langchain_core.messages import HumanMessage\n",
    "from vectrix_graphs import local_slm_demo\n",
    "\n",
    "#Ask the question\n",
    "input = [HumanMessage(content=\"What is the attention mechanism?\")]\n",
    "\n",
    "response = await local_slm_demo.ainvoke({\"messages\": input})\n",
    "print(json.dumps(response, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response['messages'][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The attention mechanism is a technique used in neural networks, particularly in natural language processing (NLP) and computer vision, to allow models to focus on specific parts of the input data that are most relevant to the task at hand. It helps improve the performance of models by enabling them to weigh the importance of different input elements dynamically.\\n\\n### Key Concepts of Attention Mechanism:\\n\\n1. **Contextual Focus**: Instead of processing all input data uniformly, the attention mechanism allows the model to selectively concentrate on certain parts of the input. This is particularly useful in tasks like translation, where certain words in a source sentence may be more relevant to specific words in the target sentence.\\n\\n2. **Weights and Scores**: The attention mechanism computes a set of attention scores that determine how much focus to place on each part of the input. These scores are typically derived from the similarity between the current state of the model (e.g., a hidden state in a recurrent neural network) and the input elements.\\n\\n3. **Softmax Function**: The attention scores are often normalized using a softmax function, which converts them into a probability distribution. This ensures that the weights sum to one, allowing the model to interpret them as probabilities of importance.\\n\\n4. **Weighted Sum**: The final output of the attention mechanism is a weighted sum of the input elements, where the weights are the attention scores. This allows the model to create a context vector that emphasizes the most relevant information.\\n\\n5. **Types of Attention**:\\n   - **Self-Attention**: A mechanism where the input sequence attends to itself, allowing the model to capture relationships between different parts of the same sequence. This is a key component of models like the Transformer.\\n   - **Cross-Attention**: Used in scenarios where one sequence attends to another, such as in encoder-decoder architectures for tasks like machine translation.\\n\\n### Applications:\\n- **Machine Translation**: Attention helps models focus on relevant words in the source language when generating words in the target language.\\n- **Image Captioning**: In computer vision, attention can help models focus on specific parts of an image when generating descriptive captions.\\n- **Text Summarization**: Attention allows models to highlight the most important sentences or phrases in a document when creating a summary.\\n\\n### Conclusion:\\nThe attention mechanism has become a foundational component in many state-of-the-art models, particularly the Transformer architecture, which relies heavily on self-attention to process sequences efficiently and effectively. Its ability to model dependencies and relationships in data has significantly advanced the field of deep learning.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "\n",
    "human = HumanMessage(content=\"What is the attention mechanism?\")\n",
    "ai = AIMessage(content=\"The attention mechanism is a technique used in neural networks to enable the model to focus on relevant parts of the input data during processing.\")\n",
    "\n",
    "messages = ChatPromptTemplate.from_messages([human, ai])\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "chain = messages | llm | StrOutputParser()\n",
    "\n",
    "chain.invoke({})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
