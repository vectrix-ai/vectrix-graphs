{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-model embeddings\n",
    "In this notebook we will showcase the usage of multimodal embeddings using the new [voyage-multimodal-3](https://blog.voyageai.com/2024/11/12/voyage-multimodal-3/) all-in-one embedding model. This model allows us to store multimodal data within the same vector space. It is a state of the art I'm currently at the top of the benchmark list for a multimodal embedding retrieval.\n",
    "\n",
    "In this example tutorial, we will focus on the following three main things:\n",
    "\n",
    "- **Setting up a vector storage**, as most vector storage solutions are not yet supporting this model out of the box. We need to manually configure vector storage to be able to store these embeddings. We'll use Weaviate in this demo.\n",
    "\n",
    "- **Storing embeddings of multimodal documents within this store**. To do this, we'll need to break apart the text and images within a single PDF file, store them as a JSON component, and then add them in a single vector space to the Weaviate store.\n",
    "\n",
    "- **Performing a similarity search based on these stored images and embeddings**. We'll write a simple query to retrieve the most similar documents based on a natural language query.\n",
    "\n",
    "To test this pipeline we'll use a PDF from an old Photography magazine located here [./files/magazine.pdf](./files/magazine.pdf).\n",
    "\n",
    "### Requirements for this example\n",
    "\n",
    "- **Weaviate**: We'll use the local Weaviate instance that is provided with the Docker Compose file.\n",
    "- **Voyage API key**: You can get a free API key from [Voyage](https://voyageai.com/).\n",
    "- **Poppler**: This utility is needed to extract the images from the PDF file. You can install it on MacOS with `brew install poppler`.\n",
    "\n",
    "## Step 1: Setting up the vector storage\n",
    "We will use weaviate in combinatation with the [voyage-multimodal-3](https://blog.voyageai.com/2024/11/12/voyage-multimodal-3/) model.\n",
    "\n",
    "| Model | Context Length (tokens) | Embedding Dimension | Description |\n",
    "|-------|------------------------|-------------------|-------------|\n",
    "| voyage-multimodal-3 | 32,000 | 1024 | Rich multimodal embedding model that can vectorize interleaved text and content-rich images, such as screenshots of PDFs, slides, tables, figures, and more. See blog post for details. |\n",
    "\n",
    "\n",
    "### Connect to Weaviate and create a new collection\n",
    "In this first step we connect to a local Weaviate instance and then create a new collection named \"multimodal\". We don't configure a vectorizer for this collection since Weaviate does not support multimodal embeddings for the voyager model yet. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import weaviate\n",
    "from weaviate.classes.config import Configure\n",
    "\n",
    "client = weaviate.connect_to_local()\n",
    "collection_name = \"multimodal\"\n",
    "\n",
    "client.collections.delete(collection_name)\n",
    "\n",
    "try:\n",
    "    client.collections.create(\n",
    "        name=collection_name,\n",
    "        vectorizer_config=Configure.Vectorizer.none() # Don't set a vectorizer for this collection\n",
    "    )\n",
    "    collection = client.collections.get(collection_name)\n",
    "except Exception:\n",
    "    collection = client.collections.get(collection_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Extracting documents and images from the PDF\n",
    "For the extraction process we use the popular Unstructured library. What we do is we iterate through the PDF file using the `hi_res` strategy. We store the image data in the metadata as an image base 64 encoded string and the text content we will store in the page_content key. \n",
    "\n",
    "This step to work the [Poppler](https://poppler.freedesktop.org/) utility needs to be installed on your system or container. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unstructured.partition.auto import partition\n",
    "\n",
    "elements = partition(\n",
    "            filename=\"./files/magazine_sample.pdf\",\n",
    "            strategy=\"hi_res\",\n",
    "            extract_image_block_types=[\"Image\", \"Table\"],\n",
    "            extract_image_block_to_payload=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unstructured.chunking.title import chunk_by_title\n",
    "\n",
    "chunks = chunk_by_title(elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unstructured.staging.base import elements_from_base64_gzipped_json\n",
    "import PIL.Image\n",
    "import io\n",
    "import base64\n",
    "\n",
    "embedding_objects = []\n",
    "embedding_metadatas = []\n",
    "\n",
    "for chunk in chunks:\n",
    "    embedding_object = []\n",
    "    metedata_dict = {\n",
    "        \"text\": chunk.to_dict()[\"text\"],\n",
    "        \"filename\": chunk.to_dict()[\"metadata\"][\"filename\"],\n",
    "        \"page_number\": chunk.to_dict()[\"metadata\"][\"page_number\"],\n",
    "        \"last_modified\": chunk.to_dict()[\"metadata\"][\"last_modified\"],\n",
    "        \"languages\": chunk.to_dict()[\"metadata\"][\"languages\"],\n",
    "        \"filetype\": chunk.to_dict()[\"metadata\"][\"filetype\"]\n",
    "    }\n",
    "    embedding_object.append(chunk.to_dict()[\"text\"])\n",
    "\n",
    "    # Add the images to the embedding object\n",
    "    if \"orig_elements\" in chunk.to_dict()[\"metadata\"]:\n",
    "        base64_elements_str = chunk.to_dict()[\"metadata\"][\"orig_elements\"]\n",
    "        eles = elements_from_base64_gzipped_json(base64_elements_str)\n",
    "        image_data = []\n",
    "        for ele in eles:\n",
    "            if ele.to_dict()[\"type\"] == \"Image\":\n",
    "                base64_image = ele.to_dict()[\"metadata\"][\"image_base64\"]\n",
    "                image_data.append(base64_image)\n",
    "                pil_image = PIL.Image.open(io.BytesIO(base64.b64decode(base64_image)))\n",
    "                # Resize image if larger than 1000x1000 while maintaining aspect ratio\n",
    "                if pil_image.size[0] > 1000 or pil_image.size[1] > 1000:\n",
    "                    ratio = min(1000/pil_image.size[0], 1000/pil_image.size[1])\n",
    "                    new_size = (int(pil_image.size[0] * ratio), int(pil_image.size[1] * ratio))\n",
    "                    pil_image = pil_image.resize(new_size, PIL.Image.Resampling.LANCZOS)\n",
    "                embedding_object.append(pil_image)\n",
    "\n",
    "        metedata_dict[\"image_data\"] = image_data\n",
    "\n",
    "\n",
    "    embedding_objects.append(embedding_object)\n",
    "    embedding_metadatas.append(metedata_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_objects[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(embedding_objects))\n",
    "print(len(embedding_metadatas))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Vectorizing the extracted data\n",
    "In this step we vectorize the extracted data using the Voyage API. We'll use the `voyage-multimodal-3` model to vectorize the text and images.\n",
    "Per chunk of data we provide an array of inputs. In this case we provide an array of strings for the text and an array of PIL images for the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import voyageai\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "vo = voyageai.Client()\n",
    "# This will automatically use the environment variable VOYAGE_API_KEY.\n",
    "# Alternatively, you can use vo = voyageai.Client(api_key=\"<your secret key>\")\n",
    "\n",
    "# Example input containing a text string and PIL image object\n",
    "inputs = embedding_objects\n",
    "# Vectorize inputs\n",
    "result = vo.multimodal_embed(\n",
    "    inputs, \n",
    "    model=\"voyage-multimodal-3\",\n",
    "    truncation=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Shape of embeddings: {len(result.embeddings)}x{len(result.embeddings[0])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Storing the embeddings in Weaviate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with collection.batch.dynamic() as batch:\n",
    "    for i, data_row in enumerate(embedding_objects):\n",
    "        batch.add_object(\n",
    "            properties=embedding_metadatas[i],\n",
    "            vector=result.embeddings[i]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = collection.query.fetch_objects(limit=2, include_vector=True)\n",
    "\n",
    "for o in response.objects:\n",
    "    print(\"METADATA:\")\n",
    "    print(o.metadata, '\\n')\n",
    "    print(\"TEXT:\")\n",
    "    print(o.properties['text'], '\\n')\n",
    "    print(\"EMBEDDING:\")\n",
    "    print(o.vector['default'][:5], '\\n-----\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Performing a similarity search and displaying the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from weaviate.classes.query import MetadataQuery\n",
    "\n",
    "question = \"What do magazines say about cats ?\"\n",
    "vector = vo.multimodal_embed([[question]], model=\"voyage-multimodal-3\")\n",
    "\n",
    "vector.embeddings[0]\n",
    "\n",
    "response = collection.query.near_vector(\n",
    "    near_vector=vector.embeddings[0], # your query vector goes here\n",
    "    limit=2,\n",
    "    return_metadata=MetadataQuery(distance=True)\n",
    ")\n",
    "\n",
    "for o in response.objects:\n",
    "    print(o.properties['text'])\n",
    "    for image_data in o.properties['image_data']:\n",
    "        # Display the image using PIL\n",
    "        img = PIL.Image.open(io.BytesIO(base64.b64decode(image_data)))\n",
    "        width, height = img.size\n",
    "        if width > 500 or height > 500:\n",
    "            ratio = min(500/width, 500/height)\n",
    "            new_size = (int(width * ratio), int(height * ratio))\n",
    "            img = img.resize(new_size)\n",
    "        display(img)\n",
    "    print(o.metadata.distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectrix Graphs Demo\n",
    "This demo showcases the same flow but with the Vectrix Graphs library. We contained the above code in classes and modules to showcase how this functionality is implemented in a LangGraph flow that can run in a production environment.\n",
    "\n",
    "### Adding the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src')\n",
    "from dotenv import load_dotenv\n",
    "from vectrix_graphs.importers.documents import multi_modal_extraction\n",
    "from vectrix_graphs.db.weaviate import Weaviate\n",
    "\n",
    "load_dotenv()\n",
    "file = './files/magazine.pdf'\n",
    "\n",
    "# Extract the documents and images from the file and the related metadata\n",
    "embedding_objects, metadatas = multi_modal_extraction(file)\n",
    "\n",
    "weaviate = Weaviate()\n",
    "# Let's re create the collection, to make sure we start from a clean state\n",
    "weaviate.remove_collection(\"multimodal_demo\")\n",
    "weaviate.create_collection(name=\"multimodal_demo\", vectorizer_config=\"voyage\")\n",
    "\n",
    "weaviate.add_multi_modal_documents(embedding_objects, metadatas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "weaviate = Weaviate()\n",
    "weaviate.set_collection(\"multimodal_demo\")\n",
    "results = weaviate.similarity_search(\"What do magazines say about cats ?\", k=10, type=\"multimodal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for result in results:\n",
    "    print(result.page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "weaviate.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-23 13:36:18,861 - vectrix_graphs.graphs.default_flow - INFO - GraphNodes initialized\u001b[0m\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../src')\n",
    "from dotenv import load_dotenv\n",
    "from vectrix_graphs.graphs.multi_modal_rag import multi_modal_graph\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "from IPython.display import Markdown, display, Image\n",
    "\n",
    "display(Image(multi_modal_graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vectrix_graphs.db.weaviate import Weaviate\n",
    "weaviate = Weaviate()\n",
    "weaviate.list_collections()\n",
    "weaviate.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running multi-modal retrieval\n",
      "Searching for What does the magazine say about cats ?\n"
     ]
    },
    {
     "ename": "WeaviateQueryError",
     "evalue": "Query call with protocol GRPC search failed with message <AioRpcError of RPC that terminated with:\n\tstatus = StatusCode.UNKNOWN\n\tdetails = \"explorer: get class: concurrentTargetVectorSearch): explorer: get class: vector search: object vector search at index multimodal_demo: get/init local shard \"vx9LGkg23vV8\", no shutdown: LazyLoadShard::preventShutdown: Unable to load shard vx9LGkg23vV8: init shard \"multimodal_demo_vx9LGkg23vV8\": init shard \"multimodal_demo_vx9LGkg23vV8\": init prop \"image_data\": value index: init disk segments: init segment segment-1732277752996229589.db: unexpected error loading segment \"/var/lib/weaviate/multimodal_demo/vx9LGkg23vV8/lsm/property_image_data_searchable/segment-1732277752996229589.db\": runtime error: slice bounds out of range [:964191095] with capacity 33073818\"\n\tdebug_error_string = \"UNKNOWN:Error received from peer  {created_time:\"2024-11-23T12:47:59.270112+00:00\", grpc_status:2, grpc_message:\"explorer: get class: concurrentTargetVectorSearch): explorer: get class: vector search: object vector search at index multimodal_demo: get/init local shard \\\"vx9LGkg23vV8\\\", no shutdown: LazyLoadShard::preventShutdown: Unable to load shard vx9LGkg23vV8: init shard \\\"multimodal_demo_vx9LGkg23vV8\\\": init shard \\\"multimodal_demo_vx9LGkg23vV8\\\": init prop \\\"image_data\\\": value index: init disk segments: init segment segment-1732277752996229589.db: unexpected error loading segment \\\"/var/lib/weaviate/multimodal_demo/vx9LGkg23vV8/lsm/property_image_data_searchable/segment-1732277752996229589.db\\\": runtime error: slice bounds out of range [:964191095] with capacity 33073818\"}\"\n>.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAioRpcError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m~/Documents/GitHub/vectrix-graphs/.venv/lib/python3.11/site-packages/weaviate/collections/grpc/query.py:804\u001b[0m, in \u001b[0;36m_QueryGRPC.__call\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    803\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection\u001b[38;5;241m.\u001b[39mgrpc_stub \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 804\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m _Retry(\u001b[38;5;241m4\u001b[39m)\u001b[38;5;241m.\u001b[39mwith_exponential_backoff(\n\u001b[1;32m    805\u001b[0m     \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m    806\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSearching in collection \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrequest\u001b[38;5;241m.\u001b[39mcollection\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    807\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection\u001b[38;5;241m.\u001b[39mgrpc_stub\u001b[38;5;241m.\u001b[39mSearch,\n\u001b[1;32m    808\u001b[0m     request,\n\u001b[1;32m    809\u001b[0m     metadata\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection\u001b[38;5;241m.\u001b[39mgrpc_headers(),\n\u001b[1;32m    810\u001b[0m     timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection\u001b[38;5;241m.\u001b[39mtimeout_config\u001b[38;5;241m.\u001b[39mquery,\n\u001b[1;32m    811\u001b[0m )\n\u001b[1;32m    812\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cast(search_get_pb2\u001b[38;5;241m.\u001b[39mSearchReply, res)\n",
      "File \u001b[0;32m~/Documents/GitHub/vectrix-graphs/.venv/lib/python3.11/site-packages/weaviate/collections/grpc/retry.py:31\u001b[0m, in \u001b[0;36m_Retry.with_exponential_backoff\u001b[0;34m(self, count, error, f, *args, **kwargs)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m e\u001b[38;5;241m.\u001b[39mcode() \u001b[38;5;241m!=\u001b[39m StatusCode\u001b[38;5;241m.\u001b[39mUNAVAILABLE:\n\u001b[0;32m---> 31\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m     32\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00merror\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m received exception: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Retrying with exponential backoff in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcount\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m seconds\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     34\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/GitHub/vectrix-graphs/.venv/lib/python3.11/site-packages/weaviate/collections/grpc/retry.py:28\u001b[0m, in \u001b[0;36m_Retry.with_exponential_backoff\u001b[0;34m(self, count, error, f, *args, **kwargs)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 28\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m AioRpcError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/Documents/GitHub/vectrix-graphs/.venv/lib/python3.11/site-packages/grpc/aio/_call.py:327\u001b[0m, in \u001b[0;36m_UnaryResponseMixin.__await__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    326\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 327\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m _create_rpc_error(\n\u001b[1;32m    328\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cython_call\u001b[38;5;241m.\u001b[39m_initial_metadata,\n\u001b[1;32m    329\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cython_call\u001b[38;5;241m.\u001b[39m_status,\n\u001b[1;32m    330\u001b[0m         )\n\u001b[1;32m    331\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mAioRpcError\u001b[0m: <AioRpcError of RPC that terminated with:\n\tstatus = StatusCode.UNKNOWN\n\tdetails = \"explorer: get class: concurrentTargetVectorSearch): explorer: get class: vector search: object vector search at index multimodal_demo: get/init local shard \"vx9LGkg23vV8\", no shutdown: LazyLoadShard::preventShutdown: Unable to load shard vx9LGkg23vV8: init shard \"multimodal_demo_vx9LGkg23vV8\": init shard \"multimodal_demo_vx9LGkg23vV8\": init prop \"image_data\": value index: init disk segments: init segment segment-1732277752996229589.db: unexpected error loading segment \"/var/lib/weaviate/multimodal_demo/vx9LGkg23vV8/lsm/property_image_data_searchable/segment-1732277752996229589.db\": runtime error: slice bounds out of range [:964191095] with capacity 33073818\"\n\tdebug_error_string = \"UNKNOWN:Error received from peer  {created_time:\"2024-11-23T12:47:59.270112+00:00\", grpc_status:2, grpc_message:\"explorer: get class: concurrentTargetVectorSearch): explorer: get class: vector search: object vector search at index multimodal_demo: get/init local shard \\\"vx9LGkg23vV8\\\", no shutdown: LazyLoadShard::preventShutdown: Unable to load shard vx9LGkg23vV8: init shard \\\"multimodal_demo_vx9LGkg23vV8\\\": init shard \\\"multimodal_demo_vx9LGkg23vV8\\\": init prop \\\"image_data\\\": value index: init disk segments: init segment segment-1732277752996229589.db: unexpected error loading segment \\\"/var/lib/weaviate/multimodal_demo/vx9LGkg23vV8/lsm/property_image_data_searchable/segment-1732277752996229589.db\\\": runtime error: slice bounds out of range [:964191095] with capacity 33073818\"}\"\n>",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mWeaviateQueryError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m config \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfigurable\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcollection_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultimodal_demo\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minclude_images\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m}}\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Run the graph\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m multi_modal_graph\u001b[38;5;241m.\u001b[39mainvoke({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: input_message}, config\u001b[38;5;241m=\u001b[39mconfig)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(response[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mcontent)\n",
      "File \u001b[0;32m~/Documents/GitHub/vectrix-graphs/.venv/lib/python3.11/site-packages/langgraph/pregel/__init__.py:1980\u001b[0m, in \u001b[0;36mPregel.ainvoke\u001b[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, **kwargs)\u001b[0m\n\u001b[1;32m   1978\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1979\u001b[0m     chunks \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m-> 1980\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mastream(\n\u001b[1;32m   1981\u001b[0m     \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m   1982\u001b[0m     config,\n\u001b[1;32m   1983\u001b[0m     stream_mode\u001b[38;5;241m=\u001b[39mstream_mode,\n\u001b[1;32m   1984\u001b[0m     output_keys\u001b[38;5;241m=\u001b[39moutput_keys,\n\u001b[1;32m   1985\u001b[0m     interrupt_before\u001b[38;5;241m=\u001b[39minterrupt_before,\n\u001b[1;32m   1986\u001b[0m     interrupt_after\u001b[38;5;241m=\u001b[39minterrupt_after,\n\u001b[1;32m   1987\u001b[0m     debug\u001b[38;5;241m=\u001b[39mdebug,\n\u001b[1;32m   1988\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   1989\u001b[0m ):\n\u001b[1;32m   1990\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stream_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1991\u001b[0m         latest \u001b[38;5;241m=\u001b[39m chunk\n",
      "File \u001b[0;32m~/Documents/GitHub/vectrix-graphs/.venv/lib/python3.11/site-packages/langgraph/pregel/__init__.py:1865\u001b[0m, in \u001b[0;36mPregel.astream\u001b[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, subgraphs)\u001b[0m\n\u001b[1;32m   1859\u001b[0m \u001b[38;5;66;03m# Similarly to Bulk Synchronous Parallel / Pregel model\u001b[39;00m\n\u001b[1;32m   1860\u001b[0m \u001b[38;5;66;03m# computation proceeds in steps, while there are channel updates\u001b[39;00m\n\u001b[1;32m   1861\u001b[0m \u001b[38;5;66;03m# channel updates from step N are only visible in step N+1\u001b[39;00m\n\u001b[1;32m   1862\u001b[0m \u001b[38;5;66;03m# channels are guaranteed to be immutable for the duration of the step,\u001b[39;00m\n\u001b[1;32m   1863\u001b[0m \u001b[38;5;66;03m# with channel updates applied only at the transition between steps\u001b[39;00m\n\u001b[1;32m   1864\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mtick(input_keys\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_channels):\n\u001b[0;32m-> 1865\u001b[0m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m runner\u001b[38;5;241m.\u001b[39matick(\n\u001b[1;32m   1866\u001b[0m         loop\u001b[38;5;241m.\u001b[39mtasks\u001b[38;5;241m.\u001b[39mvalues(),\n\u001b[1;32m   1867\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_timeout,\n\u001b[1;32m   1868\u001b[0m         retry_policy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretry_policy,\n\u001b[1;32m   1869\u001b[0m         get_waiter\u001b[38;5;241m=\u001b[39mget_waiter,\n\u001b[1;32m   1870\u001b[0m     ):\n\u001b[1;32m   1871\u001b[0m         \u001b[38;5;66;03m# emit output\u001b[39;00m\n\u001b[1;32m   1872\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m o \u001b[38;5;129;01min\u001b[39;00m output():\n\u001b[1;32m   1873\u001b[0m             \u001b[38;5;28;01myield\u001b[39;00m o\n",
      "File \u001b[0;32m~/Documents/GitHub/vectrix-graphs/.venv/lib/python3.11/site-packages/langgraph/pregel/runner.py:221\u001b[0m, in \u001b[0;36mPregelRunner.atick\u001b[0;34m(self, tasks, reraise, timeout, retry_policy, get_waiter)\u001b[0m\n\u001b[1;32m    219\u001b[0m t \u001b[38;5;241m=\u001b[39m tasks[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 221\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m arun_with_retry(\n\u001b[1;32m    222\u001b[0m         t, retry_policy, stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_astream, writer\u001b[38;5;241m=\u001b[39mwriter\n\u001b[1;32m    223\u001b[0m     )\n\u001b[1;32m    224\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    225\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m~/Documents/GitHub/vectrix-graphs/.venv/lib/python3.11/site-packages/langgraph/pregel/retry.py:118\u001b[0m, in \u001b[0;36marun_with_retry\u001b[0;34m(task, retry_policy, stream, writer)\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 118\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m task\u001b[38;5;241m.\u001b[39mproc\u001b[38;5;241m.\u001b[39mainvoke(task\u001b[38;5;241m.\u001b[39minput, config)\n\u001b[1;32m    119\u001b[0m \u001b[38;5;66;03m# if successful, end\u001b[39;00m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/GitHub/vectrix-graphs/.venv/lib/python3.11/site-packages/langgraph/utils/runnable.py:453\u001b[0m, in \u001b[0;36mRunnableSeq.ainvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    451\u001b[0m     coro \u001b[38;5;241m=\u001b[39m step\u001b[38;5;241m.\u001b[39mainvoke(\u001b[38;5;28minput\u001b[39m, config)\n\u001b[1;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ASYNCIO_ACCEPTS_CONTEXT:\n\u001b[0;32m--> 453\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mcreate_task(coro, context\u001b[38;5;241m=\u001b[39mcontext)\n\u001b[1;32m    454\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    455\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mcreate_task(coro)\n",
      "File \u001b[0;32m~/Documents/GitHub/vectrix-graphs/.venv/lib/python3.11/site-packages/langgraph/utils/runnable.py:236\u001b[0m, in \u001b[0;36mRunnableCallable.ainvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ASYNCIO_ACCEPTS_CONTEXT:\n\u001b[1;32m    235\u001b[0m     coro \u001b[38;5;241m=\u001b[39m cast(Coroutine[\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, Any], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mafunc(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs))\n\u001b[0;32m--> 236\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mcreate_task(coro, context\u001b[38;5;241m=\u001b[39mcontext)\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    238\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mafunc(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/Documents/GitHub/vectrix-graphs/examples/../src/vectrix_graphs/graphs/nodes/multi_modal_rag.py:32\u001b[0m, in \u001b[0;36mRAGNodes.multi_modal_retrieval\u001b[0;34m(self, state, config)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRunning multi-modal retrieval\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSearching for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstate[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mcontent\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 32\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweaviate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msimilarity_search\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquery\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstate\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmultimodal\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     36\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresults\u001b[39m\u001b[38;5;124m\"\u001b[39m: results}\n",
      "File \u001b[0;32m~/Documents/GitHub/vectrix-graphs/examples/../src/vectrix_graphs/db/weaviate.py:137\u001b[0m, in \u001b[0;36mWeaviate.similarity_search\u001b[0;34m(self, query, k, type)\u001b[0m\n\u001b[1;32m    135\u001b[0m vo \u001b[38;5;241m=\u001b[39m voyageai\u001b[38;5;241m.\u001b[39mClient()\n\u001b[1;32m    136\u001b[0m vector \u001b[38;5;241m=\u001b[39m vo\u001b[38;5;241m.\u001b[39mmultimodal_embed([[query]], model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvoyage-multimodal-3\u001b[39m\u001b[38;5;124m\"\u001b[39m, truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m--> 137\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnear_vector\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnear_vector\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membeddings\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    139\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mMetadataQuery\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdistance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    143\u001b[0m documents \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m results\u001b[38;5;241m.\u001b[39mobjects:\n",
      "File \u001b[0;32m~/Documents/GitHub/vectrix-graphs/.venv/lib/python3.11/site-packages/weaviate/syncify.py:23\u001b[0m, in \u001b[0;36mconvert.<locals>.sync_method\u001b[0;34m(self, __new_name, *args, **kwargs)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(method)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msync_method\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, __new_name\u001b[38;5;241m=\u001b[39mnew_name, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     22\u001b[0m     async_func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mcls\u001b[39m, __new_name)\n\u001b[0;32m---> 23\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_EventLoopSingleton\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_instance\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_until_complete\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m        \u001b[49m\u001b[43masync_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GitHub/vectrix-graphs/.venv/lib/python3.11/site-packages/weaviate/event_loop.py:42\u001b[0m, in \u001b[0;36m_EventLoop.run_until_complete\u001b[0;34m(self, f, *args, **kwargs)\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m WeaviateClosedClientError()\n\u001b[1;32m     41\u001b[0m fut \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mrun_coroutine_threadsafe(f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloop)\n\u001b[0;32m---> 42\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfut\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/share/uv/python/cpython-3.11.10-macos-aarch64-none/lib/python3.11/concurrent/futures/_base.py:456\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    454\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m--> 456\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    458\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m()\n",
      "File \u001b[0;32m~/.local/share/uv/python/cpython-3.11.10-macos-aarch64-none/lib/python3.11/concurrent/futures/_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[1;32m    400\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 401\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    403\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    404\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/GitHub/vectrix-graphs/.venv/lib/python3.11/site-packages/weaviate/collections/queries/near_vector/query.py:92\u001b[0m, in \u001b[0;36m_NearVectorQueryAsync.near_vector\u001b[0;34m(self, near_vector, certainty, distance, limit, offset, auto_limit, filters, group_by, rerank, target_vector, include_vector, return_metadata, return_properties, return_references)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnear_vector\u001b[39m(\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     29\u001b[0m     near_vector: NearVectorInputType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     43\u001b[0m     return_references: Optional[ReturnReferences[TReferences]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     44\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m QuerySearchReturnType[Properties, References, TProperties, TReferences]:\n\u001b[1;32m     45\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search for objects by vector in this collection using and vector-based similarity search.\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \n\u001b[1;32m     47\u001b[0m \u001b[38;5;124;03m    See the [docs](https://weaviate.io/developers/weaviate/search/similarity) for a more detailed explanation.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;124;03m            If the request to the Weaviate server fails.\u001b[39;00m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 92\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_query\u001b[38;5;241m.\u001b[39mnear_vector(\n\u001b[1;32m     93\u001b[0m         near_vector\u001b[38;5;241m=\u001b[39mnear_vector,\n\u001b[1;32m     94\u001b[0m         certainty\u001b[38;5;241m=\u001b[39mcertainty,\n\u001b[1;32m     95\u001b[0m         distance\u001b[38;5;241m=\u001b[39mdistance,\n\u001b[1;32m     96\u001b[0m         limit\u001b[38;5;241m=\u001b[39mlimit,\n\u001b[1;32m     97\u001b[0m         offset\u001b[38;5;241m=\u001b[39moffset,\n\u001b[1;32m     98\u001b[0m         autocut\u001b[38;5;241m=\u001b[39mauto_limit,\n\u001b[1;32m     99\u001b[0m         filters\u001b[38;5;241m=\u001b[39mfilters,\n\u001b[1;32m    100\u001b[0m         group_by\u001b[38;5;241m=\u001b[39m_GroupBy\u001b[38;5;241m.\u001b[39mfrom_input(group_by),\n\u001b[1;32m    101\u001b[0m         rerank\u001b[38;5;241m=\u001b[39mrerank,\n\u001b[1;32m    102\u001b[0m         target_vector\u001b[38;5;241m=\u001b[39mtarget_vector,\n\u001b[1;32m    103\u001b[0m         return_metadata\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parse_return_metadata(return_metadata, include_vector),\n\u001b[1;32m    104\u001b[0m         return_properties\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parse_return_properties(return_properties),\n\u001b[1;32m    105\u001b[0m         return_references\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parse_return_references(return_references),\n\u001b[1;32m    106\u001b[0m     )\n\u001b[1;32m    107\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result_to_query_or_groupby_return(\n\u001b[1;32m    108\u001b[0m         res,\n\u001b[1;32m    109\u001b[0m         _QueryOptions\u001b[38;5;241m.\u001b[39mfrom_input(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    119\u001b[0m         return_references,\n\u001b[1;32m    120\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/GitHub/vectrix-graphs/.venv/lib/python3.11/site-packages/weaviate/collections/grpc/query.py:814\u001b[0m, in \u001b[0;36m_QueryGRPC.__call\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    812\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(search_get_pb2\u001b[38;5;241m.\u001b[39mSearchReply, res)\n\u001b[1;32m    813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (AioRpcError, WeaviateRetryError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 814\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m WeaviateQueryError(\u001b[38;5;28mstr\u001b[39m(e), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGRPC search\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mWeaviateQueryError\u001b[0m: Query call with protocol GRPC search failed with message <AioRpcError of RPC that terminated with:\n\tstatus = StatusCode.UNKNOWN\n\tdetails = \"explorer: get class: concurrentTargetVectorSearch): explorer: get class: vector search: object vector search at index multimodal_demo: get/init local shard \"vx9LGkg23vV8\", no shutdown: LazyLoadShard::preventShutdown: Unable to load shard vx9LGkg23vV8: init shard \"multimodal_demo_vx9LGkg23vV8\": init shard \"multimodal_demo_vx9LGkg23vV8\": init prop \"image_data\": value index: init disk segments: init segment segment-1732277752996229589.db: unexpected error loading segment \"/var/lib/weaviate/multimodal_demo/vx9LGkg23vV8/lsm/property_image_data_searchable/segment-1732277752996229589.db\": runtime error: slice bounds out of range [:964191095] with capacity 33073818\"\n\tdebug_error_string = \"UNKNOWN:Error received from peer  {created_time:\"2024-11-23T12:47:59.270112+00:00\", grpc_status:2, grpc_message:\"explorer: get class: concurrentTargetVectorSearch): explorer: get class: vector search: object vector search at index multimodal_demo: get/init local shard \\\"vx9LGkg23vV8\\\", no shutdown: LazyLoadShard::preventShutdown: Unable to load shard vx9LGkg23vV8: init shard \\\"multimodal_demo_vx9LGkg23vV8\\\": init shard \\\"multimodal_demo_vx9LGkg23vV8\\\": init prop \\\"image_data\\\": value index: init disk segments: init segment segment-1732277752996229589.db: unexpected error loading segment \\\"/var/lib/weaviate/multimodal_demo/vx9LGkg23vV8/lsm/property_image_data_searchable/segment-1732277752996229589.db\\\": runtime error: slice bounds out of range [:964191095] with capacity 33073818\"}\"\n>."
     ]
    }
   ],
   "source": [
    "#Ask the question\n",
    "input_message = [HumanMessage(content=\"What does the magazine say about cats ?\")]\n",
    "\n",
    "config = {\"configurable\": {\"collection_name\": \"multimodal_demo\", \"include_images\": True}}\n",
    "\n",
    "# Run the graph\n",
    "response = await multi_modal_graph.ainvoke({\"messages\": input_message}, config=config)\n",
    "print(response['messages'][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'response' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mresponse\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'response' is not defined"
     ]
    }
   ],
   "source": [
    "response"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
